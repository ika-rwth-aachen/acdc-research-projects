{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Task* - Traffic Light Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Develop a methodology for the detection of traffic lights and their current state from camera images.\n",
    "\n",
    "- [Background and Motivation](#background-and-motivation)\n",
    "- [Task](#task)\n",
    "- [Required Tools and Data](#required-tools-and-data)\n",
    "- [Hints](#hints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Motivation\n",
    "\n",
    "An accurate knowledge about traffic light states is vital for fully-automated driving in urban environments. If traffic lights were equipped with the right hard- and software, V2X communication would be a reasonable way of transmitting traffic light states to automated vehicles nearby. As a fallback to V2X solutions or in situations, where V2X is not supported, it is also desirable to have a perception function dedicated to detecting traffic lights and their current state from camera images.\n",
    "\n",
    "The actual problem is two-fold: first, traffic lights need to be detected in camera images and their current state needs to be inferred; second, the algorithm needs to evaluate whether the detected traffic light has any influence on the currently planned trajectory or whether it can be ignored. This topic is supposed to only deal with the first task, namely the detection of traffic lights and their current state based on camera images.\n",
    "\n",
    "For detection, two common image processing tasks seem to be a reasonable approach:\n",
    "1. 2D object detection using bounding boxes\n",
    "1. semantic image segmentation\n",
    "\n",
    "Below is an exemplary sample from the [DriveU Traffic Light Dataset (DTLD)](https://www.uni-ulm.de/in/iui-drive-u/projekte/driveu-traffic-light-dataset/), which treats the problem as a 2D bounding box object detection task.\n",
    "\n",
    "![](./assets/DriveU-sample.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "The task is to develop a methodology (e.g., neural network-based) for the detection of traffic lights and their current state (e.g., green/yellow/red/...) from camera images.\n",
    "\n",
    "### Subtasks\n",
    "\n",
    "> ***Note:*** *The subtasks listed below do not have to be followed strictly. They serve the purpose of guiding you along your own research for this topic.*\n",
    "\n",
    "1. Research literature on existing approaches for traffic light detection.\n",
    "1. Find one or multiple suitable publicly available datasets, which you can use to train and evaluate your methodology.\n",
    "1. Decide which approach you would like to follow to tackle the task (also depends on the selected dataset(s)):\n",
    "   - 2D object detection using bounding boxes (+ potential post-processing)\n",
    "   - semantic image segmentation (+ potential post-processing)\n",
    "   - combination of both approaches\n",
    "   - something completely different\n",
    "1. Implement a data pipeline to serve the dataset data.\n",
    "1. Implement a model for your selected approach.\n",
    "1. Optionally implement required post-processing, e.g., if you first localize traffic lights and then use some other method to infer traffic light state.\n",
    "1. Train and evaluate your methodology on the selected dataset.\n",
    "1. Document your research, developed approach, and evaluations in a Jupyter notebook report. Explain and reproduce individual parts of your implemented functions with exemplary data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Tools and Data\n",
    "\n",
    "### Tools\n",
    "\n",
    "- TensorFlow\n",
    "- *(potentially)* OpenCV\n",
    "- *(as inspiration)* Image Segmentation Training Pipeline & Model *(see [ACDC Exercise: Semantic Image Segmentation](https://github.com/ika-rwth-aachen/acdc-notebooks/blob/main/section_2_sensor_data_processing/1_semantic_image_segmentation.ipynb))*\n",
    "- *(as inspiration)* 3D Object Detection Training Pipeline & Model *(see [ACDC Exercise: 3D Object Detection](https://github.com/ika-rwth-aachen/acdc-notebooks/blob/main/section_2_sensor_data_processing/5_object_detection.ipynb))*\n",
    "  - note that image object detection is 2D, but concepts like anchor boxes are applicable to both use cases\n",
    "\n",
    "### Data\n",
    "\n",
    "- *(to be found)* publicly available dataset(s) for traffic light and state detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "### Relevant ACDC Sections\n",
    "\n",
    "- **Sensor Data Processing Algorithms**\n",
    "  - Image Segmentation\n",
    "  - Object Detection"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f35c820e40155ce3a3d6b6baab4aa8cb626eff9596fe63e71a966e5e0dc1513e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('acdc-rp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
